{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba28c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import os\n",
    "from threading import Thread, Lock\n",
    "from queue import Queue\n",
    "import time\n",
    "import platform\n",
    "import re\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "CONFIG = {\n",
    "    \"FACE_MATCH_THRESHOLD\": 0.6,\n",
    "    \"PLATE_OCR_CONFIG\": r'--psm 8 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "    \"MIN_PLATE_CHARS\": 3,\n",
    "    \"FRAME_SKIP\": 3,  # Process plates every N frames\n",
    "    \"CAMERAS\": [\n",
    "        {\n",
    "            \"name\": \"Mobile\",\n",
    "            \"src\": \"http://192.168.29.231:8080/video\",\n",
    "            \"role\": \"plates\",\n",
    "            \"width\": 1280,  # Increased resolution for better plate detection\n",
    "            \"height\": 720,\n",
    "            \"fps\": 15\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Laptop\",\n",
    "            \"src\": 0,\n",
    "            \"role\": \"faces\",\n",
    "            \"width\": 640,  # Increased resolution for better face detection\n",
    "            \"height\": 480,\n",
    "            \"fps\": 20\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ========== INITIALIZATION ==========\n",
    "print(\"üîç Loading reference faces...\")\n",
    "try:\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    \n",
    "    reference_folder = \"reference_images\"\n",
    "    os.makedirs(reference_folder, exist_ok=True)\n",
    "    reference_image_path = os.path.join(reference_folder, \"person.jpg\")\n",
    "    \n",
    "    if not os.path.exists(reference_image_path):\n",
    "        raise FileNotFoundError(f\"Reference image not found at {reference_image_path}\")\n",
    "    \n",
    "    ref_image = face_recognition.load_image_file(reference_image_path)\n",
    "    ref_encodings = face_recognition.face_encodings(ref_image)\n",
    "    \n",
    "    if not ref_encodings:\n",
    "        raise ValueError(\"No faces found in reference image\")\n",
    "    \n",
    "    known_face_encodings.append(ref_encodings[0])\n",
    "    known_face_names.append(\"Authorized Person\")\n",
    "    print(f\"‚úÖ {len(known_face_encodings)} reference faces loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Face load error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Tesseract setup\n",
    "if platform.system() == 'Windows':\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# ========== OPTIMIZED VIDEO STREAM ==========\n",
    "class VideoStream:\n",
    "    def __init__(self, src, name=\"Camera\", width=640, height=480, fps=30):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        if not self.stream.isOpened():\n",
    "            raise RuntimeError(f\"Cannot open {name} camera\")\n",
    "        \n",
    "        self.stream.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "        self.stream.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "        self.stream.set(cv2.CAP_PROP_FPS, fps)\n",
    "        self.stream.set(cv2.CAP_PROP_BUFFERSIZE, 2)  # Increased buffer size slightly\n",
    "        self.name = name\n",
    "        self.role = \"faces\" if name == \"Laptop\" else \"plates\"\n",
    "        self.frame_queue = Queue(maxsize=2)\n",
    "        self.lock = Lock()\n",
    "        self.running = False\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "    def start(self):\n",
    "        self.running = True\n",
    "        self.thread = Thread(target=self.update, daemon=True)\n",
    "        self.thread.start()\n",
    "        return self\n",
    "    \n",
    "    def update(self):\n",
    "        while self.running:\n",
    "            ret, frame = self.stream.read()\n",
    "            if ret:\n",
    "                # Check if frame matches the requested dimensions, if not, resize\n",
    "                if frame.shape[1] != self.width or frame.shape[0] != self.height:\n",
    "                    frame = cv2.resize(frame, (self.width, self.height))\n",
    "                \n",
    "                with self.lock:\n",
    "                    if self.frame_queue.full():\n",
    "                        self.frame_queue.get()\n",
    "                    self.frame_queue.put(frame)\n",
    "            time.sleep(0.01)  # More frequent updates\n",
    "    \n",
    "    def read(self):\n",
    "        with self.lock:\n",
    "            return self.frame_queue.get() if not self.frame_queue.empty() else None\n",
    "        \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join()\n",
    "        self.stream.release()\n",
    "\n",
    "# ========== PROCESSING FUNCTIONS ==========\n",
    "def detect_faces(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Convert to RGB (face_recognition uses RGB)\n",
    "        rgb_frame = frame[:, :, ::-1]\n",
    "        \n",
    "        # Scale down for faster processing if needed\n",
    "        scale = 0.5\n",
    "        small_frame = cv2.resize(rgb_frame, (0, 0), fx=scale, fy=scale)\n",
    "        \n",
    "        # Find face locations using HOG (faster than CNN)\n",
    "        face_locations = face_recognition.face_locations(small_frame, model=\"hog\")\n",
    "        face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "        \n",
    "        # Draw debug info\n",
    "        cv2.putText(frame, f\"Faces found: {len(face_locations)}\", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        \n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Scale back up face locations\n",
    "            top = int(top / scale)\n",
    "            right = int(right / scale)\n",
    "            bottom = int(bottom / scale)\n",
    "            left = int(left / scale)\n",
    "            \n",
    "            matches = face_recognition.compare_faces(\n",
    "                known_face_encodings, \n",
    "                face_encoding, \n",
    "                tolerance=CONFIG[\"FACE_MATCH_THRESHOLD\"]\n",
    "            )\n",
    "            \n",
    "            if True in matches:\n",
    "                # Known face - green box\n",
    "                color = (0, 0, 255)\n",
    "                name = \"Got Em\"\n",
    "            else:\n",
    "                # Unknown face - red box\n",
    "                color = (80, 80, 80)\n",
    "                name = \"Unidentified\"\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        return frame\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Face detection error: {e}\")\n",
    "        return frame\n",
    "\n",
    "def detect_plates(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        gray = clahe.apply(gray)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        # Apply adaptive thresholding\n",
    "        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                     cv2.THRESH_BINARY_INV, 11, 2)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Debug info\n",
    "        cv2.putText(frame, f\"Contours: {len(contours)}\", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "        \n",
    "        # Filter contours by area\n",
    "        contours = [c for c in contours if cv2.contourArea(c) > 1000]\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]  # Top 5 candidates\n",
    "        \n",
    "        for contour in contours:\n",
    "            peri = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "            \n",
    "            # More relaxed shape condition - 4-sided or more\n",
    "            if 4 <= len(approx) <= 6:\n",
    "                x, y, w, h = cv2.boundingRect(approx)\n",
    "                aspect_ratio = w / float(h)\n",
    "                \n",
    "                # License plate aspect ratio check\n",
    "                if 2.0 < aspect_ratio < 6.0:\n",
    "                    plate_img = gray[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # Display potential license plate region\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "                    \n",
    "                    # Check plate size before OCR\n",
    "                    if plate_img.shape[0] > 0 and plate_img.shape[1] > 0:\n",
    "                        # Apply additional preprocessing to the plate region\n",
    "                        plate_img = cv2.resize(plate_img, (0, 0), fx=2, fy=2)  # Upscale\n",
    "                        plate_img = cv2.GaussianBlur(plate_img, (3, 3), 0)\n",
    "                        _, plate_img = cv2.threshold(plate_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "                        \n",
    "                        # OCR with Tesseract\n",
    "                        text = pytesseract.image_to_string(\n",
    "                            plate_img,\n",
    "                            config=CONFIG[\"PLATE_OCR_CONFIG\"]\n",
    "                        )\n",
    "                        clean_text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "                        \n",
    "                        if len(clean_text) >= CONFIG[\"MIN_PLATE_CHARS\"]:\n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                            cv2.putText(frame, f\"PLATE: {clean_text}\", \n",
    "                                       (x, y-15), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                       0.7, (255, 0, 0), 2)\n",
    "        \n",
    "        return frame\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Plate detection error: {e}\")\n",
    "        return frame\n",
    "\n",
    "# ========== MAIN EXECUTION ==========\n",
    "def main():\n",
    "    print(\"üì∑ Starting camera streams...\")\n",
    "    cameras = []\n",
    "    for cam in CONFIG[\"CAMERAS\"]:\n",
    "        try:\n",
    "            camera = VideoStream(\n",
    "                cam[\"src\"],\n",
    "                cam[\"name\"],\n",
    "                cam[\"width\"],\n",
    "                cam[\"height\"],\n",
    "                cam.get(\"fps\", 15)\n",
    "            ).start()\n",
    "            cameras.append(camera)\n",
    "            print(f\"  ‚úÖ {cam['name']} camera initialized for {cam['role']} - {cam['width']}x{cam['height']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Failed to initialize {cam['name']} camera: {e}\")\n",
    "            cameras.append(None)\n",
    "    \n",
    "    try:\n",
    "        # Create windows\n",
    "        for cam in CONFIG[\"CAMERAS\"]:\n",
    "            cv2.namedWindow(cam[\"name\"] + \" Feed\", cv2.WINDOW_NORMAL)\n",
    "            if cam[\"name\"] == \"Laptop\":\n",
    "                cv2.resizeWindow(cam[\"name\"] + \" Feed\", 640, 480)\n",
    "            else:\n",
    "                cv2.resizeWindow(cam[\"name\"] + \" Feed\", 800, 600)\n",
    "        \n",
    "        print(\"üöÄ Starting surveillance system (Press Q to quit)...\")\n",
    "        frame_counter = 0\n",
    "        \n",
    "        while True:\n",
    "            start_time = time.time()\n",
    "            \n",
    "            for camera in cameras:\n",
    "                if camera is None:\n",
    "                    continue\n",
    "                \n",
    "                frame = camera.read()\n",
    "                if frame is None:\n",
    "                    continue\n",
    "                \n",
    "                # Role-based processing\n",
    "                if camera.role == \"faces\":\n",
    "                    processed_frame = detect_faces(frame)\n",
    "                else:\n",
    "                    if frame_counter % CONFIG[\"FRAME_SKIP\"] == 0:\n",
    "                        processed_frame = detect_plates(frame)\n",
    "                    else:\n",
    "                        processed_frame = frame\n",
    "                \n",
    "                if processed_frame is not None:\n",
    "                    # Add camera resolution info\n",
    "                    cv2.putText(processed_frame, \n",
    "                               f\"{processed_frame.shape[1]}x{processed_frame.shape[0]}\", \n",
    "                               (10, processed_frame.shape[0] - 10), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    \n",
    "                    cv2.imshow(camera.name + \" Feed\", processed_frame)\n",
    "            \n",
    "            frame_counter += 1\n",
    "            \n",
    "            # Exit on Q key\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            # Maintain target FPS\n",
    "            elapsed = time.time() - start_time\n",
    "            target_delay = 1/25  # ~25 FPS combined (relaxed from 30 to accommodate higher resolution)\n",
    "            if elapsed < target_delay:\n",
    "                time.sleep(target_delay - elapsed)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Received interrupt signal\")\n",
    "    except Exception as e:\n",
    "        print(f\"üî• Critical error: {e}\")\n",
    "    finally:\n",
    "        print(\"üõë Stopping system...\")\n",
    "        for camera in cameras:\n",
    "            if camera is not None:\n",
    "                camera.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"‚úÖ System stopped cleanly\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
