{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd25af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading reference faces...\n",
      "‚úÖ 1 reference faces loaded\n",
      "‚úÖ Loaded 2 offender license plates\n",
      "üì∑ Starting camera streams...\n",
      "  ‚úÖ Mobile camera initialized for plates - 640x360\n",
      "  ‚úÖ Laptop camera initialized for faces - 480x360\n",
      "üöÄ Starting surveillance system (Press Q to quit)...\n",
      "üõë Stopping system...\n",
      "‚úÖ System stopped cleanly\n",
      "üìä Final Stats:\n",
      "  - Total plates detected: 0\n",
      "  - Offender plates matched: 0\n",
      "  - CSV saved to: csvs/all_license_plates.csv\n",
      "  - OCR Method Success Rates:\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import os\n",
    "from threading import Thread, Lock\n",
    "from queue import Queue\n",
    "import time\n",
    "import platform\n",
    "import re\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# ========== OPTIMIZED CONFIGURATION ==========\n",
    "CONFIG = {\n",
    "    \"FACE_MATCH_THRESHOLD\": 0.6,\n",
    "    \"PLATE_OCR_CONFIG\": r'--psm 8 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "    \"MIN_PLATE_CHARS\": 3,\n",
    "    \"FRAME_SKIP\": 5,  # Increased from 3 to 5\n",
    "    \"OCR_CONFIDENCE_THRESHOLD\": 40.0,\n",
    "    \"DETECTION_COOLDOWN\": 2.0,  # Seconds between processing the same plate\n",
    "    \"CSV_PATHS\": {\n",
    "        \"OFFENDER_PLATES\": \"csvs/offender_license_plates.csv\",\n",
    "        \"ALL_PLATES\": \"csvs/all_license_plates.csv\"\n",
    "    },\n",
    "    \"CAMERAS\": [\n",
    "        {\n",
    "            \"name\": \"Mobile\",\n",
    "            \"src\": \"http://192.168.29.231:8080/video\",\n",
    "            \"role\": \"plates\",\n",
    "            \"width\": 640,  # Reduced from 1280 for better performance\n",
    "            \"height\": 360,  # Reduced from 720 for better performance\n",
    "            \"fps\": 15\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Laptop\",\n",
    "            \"src\": 0,\n",
    "            \"role\": \"faces\",\n",
    "            \"width\": 480,  # Reduced from 640 for better performance\n",
    "            \"height\": 360,  # Reduced from 480\n",
    "            \"fps\": 20\n",
    "        }\n",
    "    ],\n",
    "    # Choose only one pipeline variant for plates\n",
    "    \"PLATE_PIPELINE\": \"adaptive\"  # Options: \"adaptive\", \"edge\", \"morph\", \"bilateral\"\n",
    "}\n",
    "\n",
    "# ========== INITIALIZATION ==========\n",
    "print(\"üîç Loading reference faces...\")\n",
    "try:\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    \n",
    "    reference_folder = \"reference_images\"\n",
    "    os.makedirs(reference_folder, exist_ok=True)\n",
    "    reference_image_path = os.path.join(reference_folder, \"person.jpg\")\n",
    "    \n",
    "    if not os.path.exists(reference_image_path):\n",
    "        raise FileNotFoundError(f\"Reference image not found at {reference_image_path}\")\n",
    "    \n",
    "    ref_image = face_recognition.load_image_file(reference_image_path)\n",
    "    ref_encodings = face_recognition.face_encodings(ref_image)\n",
    "    \n",
    "    if not ref_encodings:\n",
    "        raise ValueError(\"No faces found in reference image\")\n",
    "    \n",
    "    known_face_encodings.append(ref_encodings[0])\n",
    "    known_face_names.append(\"Authorized Person\")\n",
    "    print(f\"‚úÖ {len(known_face_encodings)} reference faces loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Face load error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Tesseract setup\n",
    "if platform.system() == 'Windows':\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Create CSV directory and files if they don't exist\n",
    "os.makedirs(\"csvs\", exist_ok=True)\n",
    "\n",
    "# Initialize CSV file for all license plates if it doesn't exist\n",
    "if not os.path.exists(CONFIG[\"CSV_PATHS\"][\"ALL_PLATES\"]):\n",
    "    with open(CONFIG[\"CSV_PATHS\"][\"ALL_PLATES\"], 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['timestamp', 'license_plate', 'confidence', 'is_offender'])\n",
    "    print(f\"‚úÖ Created {CONFIG['CSV_PATHS']['ALL_PLATES']}\")\n",
    "\n",
    "# Load offender license plates\n",
    "offender_plates = set()\n",
    "try:\n",
    "    if os.path.exists(CONFIG[\"CSV_PATHS\"][\"OFFENDER_PLATES\"]):\n",
    "        offender_df = pd.read_csv(CONFIG[\"CSV_PATHS\"][\"OFFENDER_PLATES\"])\n",
    "        if 'license_plate' in offender_df.columns:\n",
    "            offender_plates = set(plate.strip().upper() for plate in offender_df['license_plate'].astype(str) if plate.strip())\n",
    "            print(f\"‚úÖ Loaded {len(offender_plates)} offender license plates\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è No 'license_plate' column found in {CONFIG['CSV_PATHS']['OFFENDER_PLATES']}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Offender plates file not found at {CONFIG['CSV_PATHS']['OFFENDER_PLATES']}\")\n",
    "        # Create an empty file with header\n",
    "        with open(CONFIG[\"CSV_PATHS\"][\"OFFENDER_PLATES\"], 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['license_plate'])\n",
    "        print(f\"‚úÖ Created empty offender plates file\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading offender plates: {e}\")\n",
    "    offender_plates = set()\n",
    "\n",
    "# Statistics tracking\n",
    "stats = {\n",
    "    \"plates_matched\": 0,\n",
    "    \"plates_current_frame\": 0,\n",
    "    \"faces_detected\": 0,\n",
    "    \"faces_matched\": 0,\n",
    "    \"plates_detected_total\": 0,\n",
    "    \"last_detected_plates\": {},  # Changed to dict to track times: {plate: timestamp}\n",
    "    \"face_detection_last_run\": 0,  # Track when we last ran face detection\n",
    "    \"face_resize_factor\": 0.5,  # Start with 0.5, adjust dynamically\n",
    "    \"frame_counter\": 0,\n",
    "    \"fps_history\": []\n",
    "}\n",
    "\n",
    "# ========== OPTIMIZED VIDEO STREAM ==========\n",
    "class VideoStream:\n",
    "    def __init__(self, src, name=\"Camera\", width=640, height=480, fps=30):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        if not self.stream.isOpened():\n",
    "            raise RuntimeError(f\"Cannot open {name} camera\")\n",
    "        \n",
    "        self.stream.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "        self.stream.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "        self.stream.set(cv2.CAP_PROP_FPS, fps)\n",
    "        self.stream.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n",
    "        self.name = name\n",
    "        self.role = \"faces\" if name == \"Laptop\" else \"plates\"\n",
    "        self.frame_queue = Queue(maxsize=2)\n",
    "        self.lock = Lock()\n",
    "        self.running = False\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.last_read_time = time.time()\n",
    "        \n",
    "    def start(self):\n",
    "        self.running = True\n",
    "        self.thread = Thread(target=self.update, daemon=True)\n",
    "        self.thread.start()\n",
    "        return self\n",
    "    \n",
    "    def update(self):\n",
    "        while self.running:\n",
    "            ret, frame = self.stream.read()\n",
    "            if ret:\n",
    "                # Only resize if needed\n",
    "                if frame.shape[1] != self.width or frame.shape[0] != self.height:\n",
    "                    frame = cv2.resize(frame, (self.width, self.height))\n",
    "                \n",
    "                with self.lock:\n",
    "                    if self.frame_queue.full():\n",
    "                        self.frame_queue.get()\n",
    "                    self.frame_queue.put(frame)\n",
    "            time.sleep(0.02)  # Reduced update frequency\n",
    "    \n",
    "    def read(self):\n",
    "        with self.lock:\n",
    "            if self.frame_queue.empty():\n",
    "                return None\n",
    "            frame = self.frame_queue.get()\n",
    "            self.last_read_time = time.time()\n",
    "            return frame\n",
    "        \n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join()\n",
    "        self.stream.release()\n",
    "\n",
    "# ========== CSV HANDLING ==========\n",
    "def save_license_plate(plate_text, confidence=None):\n",
    "    \"\"\"Save a license plate to the CSV file with optional confidence score\"\"\"\n",
    "    # Check if we've seen this plate recently\n",
    "    current_time = time.time()\n",
    "    if plate_text in stats[\"last_detected_plates\"]:\n",
    "        # Only process if it's been more than the cooldown period\n",
    "        if current_time - stats[\"last_detected_plates\"][plate_text] < CONFIG[\"DETECTION_COOLDOWN\"]:\n",
    "            return  # Skip this detection, too soon\n",
    "    \n",
    "    # Update the timestamp for this plate\n",
    "    stats[\"last_detected_plates\"][plate_text] = current_time\n",
    "    \n",
    "    # Save the plate data\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    is_offender = \"Yes\" if plate_text in offender_plates else \"No\"\n",
    "    \n",
    "    try:\n",
    "        with open(CONFIG[\"CSV_PATHS\"][\"ALL_PLATES\"], 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if confidence is not None:\n",
    "                # Include confidence score and offender status\n",
    "                writer.writerow([timestamp, plate_text, f\"{confidence:.1f}\", is_offender])\n",
    "            else:\n",
    "                # Backward compatibility\n",
    "                writer.writerow([timestamp, plate_text, \"N/A\", is_offender])\n",
    "                \n",
    "        stats[\"plates_detected_total\"] += 1\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error saving plate to CSV: {e}\")\n",
    "\n",
    "# ========== PROCESSING FUNCTIONS ==========\n",
    "def detect_faces(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Implement time-based throttling for face detection\n",
    "        current_time = time.time()\n",
    "        if current_time - stats[\"face_detection_last_run\"] < 0.1:  # Run at max 10 fps\n",
    "            return frame  # Skip face detection this frame\n",
    "        \n",
    "        stats[\"face_detection_last_run\"] = current_time\n",
    "        \n",
    "        # Reset face counters for this frame\n",
    "        stats[\"faces_detected\"] = 0\n",
    "        stats[\"faces_matched\"] = 0\n",
    "        \n",
    "        # Convert to RGB (face_recognition uses RGB)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Dynamic scaling based on performance\n",
    "        scale = stats[\"face_resize_factor\"]\n",
    "        small_frame = cv2.resize(rgb_frame, (0, 0), fx=scale, fy=scale)\n",
    "        \n",
    "        # Find face locations using HOG (faster than CNN)\n",
    "        face_locations = face_recognition.face_locations(small_frame, model=\"hog\")\n",
    "        \n",
    "        # Adjust scale factor based on processing time\n",
    "        process_time = time.time() - current_time\n",
    "        if process_time > 0.1:  # If processing takes > 100ms\n",
    "            stats[\"face_resize_factor\"] = max(0.25, stats[\"face_resize_factor\"] - 0.05)  # Reduce scale\n",
    "        elif process_time < 0.05 and stats[\"face_resize_factor\"] < 0.5:  # If processing is fast\n",
    "            stats[\"face_resize_factor\"] = min(0.5, stats[\"face_resize_factor\"] + 0.05)  # Increase scale\n",
    "        \n",
    "        # Only compute encodings if we have faces (saves computation)\n",
    "        if face_locations:\n",
    "            face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "        else:\n",
    "            face_encodings = []\n",
    "        \n",
    "        # Update stats\n",
    "        stats[\"faces_detected\"] = len(face_locations)\n",
    "        \n",
    "        # Draw debug info\n",
    "        cv2.putText(frame, f\"Faces: {stats['faces_detected']}\", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        \n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Scale back up face locations\n",
    "            top = int(top / scale)\n",
    "            right = int(right / scale)\n",
    "            bottom = int(bottom / scale)\n",
    "            left = int(left / scale)\n",
    "            \n",
    "            matches = face_recognition.compare_faces(\n",
    "                known_face_encodings, \n",
    "                face_encoding, \n",
    "                tolerance=CONFIG[\"FACE_MATCH_THRESHOLD\"]\n",
    "            )\n",
    "            \n",
    "            if True in matches:\n",
    "                # Known face - green box\n",
    "                color = (0, 0, 255)\n",
    "                name = \"Got Em\"\n",
    "                stats[\"faces_matched\"] += 1\n",
    "            else:\n",
    "                # Unknown face - gray box\n",
    "                color = (80, 80, 80)\n",
    "                name = \"Unidentified\"\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Add match stats\n",
    "        cv2.putText(frame, f\"Matches: {stats['faces_matched']}/{stats['faces_detected']}\", \n",
    "                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        \n",
    "        return frame\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Face detection error: {e}\")\n",
    "        return frame\n",
    "\n",
    "def preprocess_plate_image(plate_img):\n",
    "    \"\"\"Apply a single, optimized preprocessing pipeline to plate image\"\"\"\n",
    "    # Choose one preprocessing pipeline based on configuration\n",
    "    pipeline = CONFIG.get(\"PLATE_PIPELINE\", \"adaptive\")\n",
    "    \n",
    "    if pipeline == \"edge\":\n",
    "        # Edge-based preprocessing\n",
    "        blurred = cv2.GaussianBlur(plate_img, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "        return edges\n",
    "    \n",
    "    elif pipeline == \"morph\":\n",
    "        # Morphological preprocessing\n",
    "        _, thresh = cv2.threshold(plate_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        return cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    elif pipeline == \"bilateral\":\n",
    "        # Bilateral filtering\n",
    "        bilateral = cv2.bilateralFilter(plate_img, 11, 17, 17)\n",
    "        _, thresh = cv2.threshold(bilateral, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        return thresh\n",
    "    \n",
    "    else:  # Default to adaptive\n",
    "        # Adaptive thresholding (most reliable)\n",
    "        return cv2.adaptiveThreshold(plate_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                   cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "def detect_plates(frame):\n",
    "    if frame is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Only process every Nth frame based on FRAME_SKIP\n",
    "        stats[\"frame_counter\"] += 1\n",
    "        if stats[\"frame_counter\"] % CONFIG[\"FRAME_SKIP\"] != 0:\n",
    "            # Display current stats without processing\n",
    "            cv2.putText(frame, f\"Plates: {stats['plates_current_frame']}\", \n",
    "                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Offenders: {stats['plates_matched']}\", \n",
    "                       (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, f\"Total: {stats['plates_detected_total']}\", \n",
    "                       (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "            return frame\n",
    "        \n",
    "        # Reset plate counter for this frame\n",
    "        stats[\"plates_current_frame\"] = 0\n",
    "        detected_plates = []\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply CLAHE for better contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        gray = clahe.apply(gray)\n",
    "        \n",
    "        # Choose a single edge detection method (faster)\n",
    "        # Using Canny for edge detection (faster than combined Sobel)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        edges = cv2.Canny(blurred, 50, 150)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Filter contours by area and sort by size\n",
    "        contours = [c for c in contours if 500 < cv2.contourArea(c) < 50000]\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]  # Reduced candidates for speed\n",
    "        \n",
    "        # Debug info\n",
    "        cv2.putText(frame, f\"Contours: {len(contours)}\", \n",
    "                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "        \n",
    "        for contour in contours:\n",
    "            peri = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "            \n",
    "            # Check if contour is roughly quadrilateral\n",
    "            if 4 <= len(approx) <= 8:\n",
    "                x, y, w, h = cv2.boundingRect(approx)\n",
    "                aspect_ratio = w / float(h)\n",
    "                \n",
    "                # License plate aspect ratio range\n",
    "                if 1.5 < aspect_ratio < 7.0:\n",
    "                    # Extract the plate region\n",
    "                    plate_img = gray[max(0, y-5):min(frame.shape[0], y+h+5), \n",
    "                                    max(0, x-5):min(frame.shape[1], x+w+5)]\n",
    "                    \n",
    "                    # Check plate size before OCR\n",
    "                    if plate_img.shape[0] > 15 and plate_img.shape[1] > 15:\n",
    "                        # Resize for better OCR - ensure minimum width\n",
    "                        scale_factor = max(1.5, 150 / plate_img.shape[1])\n",
    "                        plate_img = cv2.resize(plate_img, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "                        \n",
    "                        # Apply a single optimized preprocessing pipeline\n",
    "                        processed_plate = preprocess_plate_image(plate_img)\n",
    "                        \n",
    "                        # Try OCR with just one or two configs instead of 12 different combinations\n",
    "                        config = CONFIG[\"PLATE_OCR_CONFIG\"]\n",
    "                        try:\n",
    "                            # Run OCR once with the optimized config\n",
    "                            result = pytesseract.image_to_data(processed_plate, config=config, \n",
    "                                                            output_type=pytesseract.Output.DICT)\n",
    "                            \n",
    "                            # Extract text and confidence\n",
    "                            confidences = [int(conf) for conf in result['conf'] if conf != '-1']\n",
    "                            \n",
    "                            if confidences:  # If we got any valid text\n",
    "                                avg_confidence = sum(confidences) / len(confidences)\n",
    "                                text = pytesseract.image_to_string(processed_plate, config=config)\n",
    "                                clean_text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "                                \n",
    "                                # Only process if confidence is good and text length is reasonable\n",
    "                                if (len(clean_text) >= CONFIG[\"MIN_PLATE_CHARS\"] and \n",
    "                                    avg_confidence >= CONFIG[\"OCR_CONFIDENCE_THRESHOLD\"]):\n",
    "                                    \n",
    "                                    stats[\"plates_current_frame\"] += 1\n",
    "                                    detected_plates.append(clean_text)\n",
    "                                    \n",
    "                                    # Add confidence to display\n",
    "                                    confidence_text = f\"{avg_confidence:.1f}% conf\"\n",
    "                                    \n",
    "                                    # Add plate overlay\n",
    "                                    if clean_text in offender_plates:\n",
    "                                        # Red box for offender plate\n",
    "                                        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 3)\n",
    "                                        cv2.putText(frame, f\"OFFENDER: {clean_text}\", \n",
    "                                                (x, y-25), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                                0.7, (0, 0, 255), 2)\n",
    "                                        cv2.putText(frame, confidence_text, \n",
    "                                                (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                                0.5, (0, 0, 255), 1)\n",
    "                                        stats[\"plates_matched\"] += 1\n",
    "                                    else:\n",
    "                                        # Blue box for normal plate\n",
    "                                        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                                        cv2.putText(frame, f\"PLATE: {clean_text}\", \n",
    "                                                (x, y-25), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                                0.7, (255, 0, 0), 2)\n",
    "                                        cv2.putText(frame, confidence_text, \n",
    "                                                (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                                0.5, (255, 0, 0), 1)\n",
    "                                    \n",
    "                                    # Save plate to CSV with confidence score\n",
    "                                    save_license_plate(clean_text, avg_confidence)\n",
    "                        except Exception as e:\n",
    "                            # Just continue with next contour if OCR fails\n",
    "                            continue\n",
    "        \n",
    "        # Display stats on frame\n",
    "        cv2.putText(frame, f\"Plates this frame: {stats['plates_current_frame']}\", \n",
    "                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Offender matches: {stats['plates_matched']}\", \n",
    "                   (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"Total plates: {stats['plates_detected_total']}\", \n",
    "                   (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "        \n",
    "        # Prune old detections from the cache\n",
    "        current_time = time.time()\n",
    "        stats[\"last_detected_plates\"] = {\n",
    "            plate: timestamp for plate, timestamp in stats[\"last_detected_plates\"].items() \n",
    "            if current_time - timestamp < CONFIG[\"DETECTION_COOLDOWN\"] * 3\n",
    "        }\n",
    "        \n",
    "        return frame\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Plate detection error: {e}\")\n",
    "        return frame\n",
    "\n",
    "# ========== MAIN EXECUTION ==========\n",
    "def main():\n",
    "    print(\"üì∑ Starting camera streams...\")\n",
    "    cameras = []\n",
    "    for cam in CONFIG[\"CAMERAS\"]:\n",
    "        try:\n",
    "            camera = VideoStream(\n",
    "                cam[\"src\"],\n",
    "                cam[\"name\"],\n",
    "                cam[\"width\"],\n",
    "                cam[\"height\"],\n",
    "                cam.get(\"fps\", 15)\n",
    "            ).start()\n",
    "            cameras.append(camera)\n",
    "            print(f\"  ‚úÖ {cam['name']} camera initialized for {cam['role']} - {cam['width']}x{cam['height']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Failed to initialize {cam['name']} camera: {e}\")\n",
    "            cameras.append(None)\n",
    "    \n",
    "    try:\n",
    "        # Create windows\n",
    "        for cam in CONFIG[\"CAMERAS\"]:\n",
    "            cv2.namedWindow(cam[\"name\"] + \" Feed\", cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow(cam[\"name\"] + \" Feed\", cam[\"width\"], cam[\"height\"])\n",
    "        \n",
    "        print(\"üöÄ Starting surveillance system (Press Q to quit)...\")\n",
    "        last_time = time.time()\n",
    "        fps_display_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            loop_start_time = time.time()\n",
    "            \n",
    "            for camera in cameras:\n",
    "                if camera is None:\n",
    "                    continue\n",
    "                \n",
    "                frame = camera.read()\n",
    "                if frame is None:\n",
    "                    continue\n",
    "                \n",
    "                # Role-based processing\n",
    "                if camera.role == \"faces\":\n",
    "                    processed_frame = detect_faces(frame)\n",
    "                else:\n",
    "                    processed_frame = detect_plates(frame)\n",
    "                \n",
    "                if processed_frame is not None:\n",
    "                    # Calculate and display FPS (but update display less frequently)\n",
    "                    current_time = time.time()\n",
    "                    fps = 1 / (current_time - last_time) if (current_time - last_time) > 0 else 0\n",
    "                    last_time = current_time\n",
    "                    \n",
    "                    # Add to FPS history\n",
    "                    stats[\"fps_history\"].append(fps)\n",
    "                    if len(stats[\"fps_history\"]) > 30:\n",
    "                        stats[\"fps_history\"].pop(0)\n",
    "                    avg_fps = sum(stats[\"fps_history\"]) / len(stats[\"fps_history\"])\n",
    "                    \n",
    "                    # Update FPS display only every half second to reduce CPU usage\n",
    "                    if current_time - fps_display_time > 0.5:\n",
    "                        fps_display_time = current_time\n",
    "                        fps_text = f\"{processed_frame.shape[1]}x{processed_frame.shape[0]} | FPS: {avg_fps:.1f}\"\n",
    "                        \n",
    "                        # Create a black background for FPS text\n",
    "                        cv2.rectangle(processed_frame, \n",
    "                                    (5, processed_frame.shape[0] - 30), \n",
    "                                    (250, processed_frame.shape[0] - 5), \n",
    "                                    (0, 0, 0), -1)\n",
    "                        \n",
    "                        cv2.putText(processed_frame, fps_text, \n",
    "                                   (10, processed_frame.shape[0] - 10), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "                    \n",
    "                    cv2.imshow(camera.name + \" Feed\", processed_frame)\n",
    "            \n",
    "            # Exit on Q key\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            # Intelligent frame rate control\n",
    "            elapsed = time.time() - loop_start_time\n",
    "            target_delay = 1/25  # Target ~25 FPS overall\n",
    "            if elapsed < target_delay:\n",
    "                time.sleep(target_delay - elapsed)\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nüõë Received interrupt signal\")\n",
    "    except Exception as e:\n",
    "        print(f\"üî• Critical error: {e}\")\n",
    "    finally:\n",
    "        print(\"üõë Stopping system...\")\n",
    "        for camera in cameras:\n",
    "            if camera is not None:\n",
    "                camera.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"‚úÖ System stopped cleanly\")\n",
    "        print(f\"üìä Final Stats:\")\n",
    "        print(f\"  - Total plates detected: {stats['plates_detected_total']}\")\n",
    "        print(f\"  - Offender plates matched: {stats['plates_matched']}\")\n",
    "        print(f\"  - CSV saved to: {CONFIG['CSV_PATHS']['ALL_PLATES']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, WebSocket, WebSocketDisconnect\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import uvicorn\n",
    "import json\n",
    "import asyncio\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import pytesseract\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import platform\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI(title=\"Surveillance System ML Service\")\n",
    "\n",
    "# Add CORS middleware\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # In production, replace with specific origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "CONFIG = {\n",
    "    \"FACE_MATCH_THRESHOLD\": 0.6,\n",
    "    \"PLATE_OCR_CONFIG\": r'--psm 8 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',\n",
    "    \"MIN_PLATE_CHARS\": 3,\n",
    "    \"FRAME_SKIP\": 3,  # Process plates every N frames\n",
    "}\n",
    "\n",
    "# Tesseract setup\n",
    "if platform.system() == 'Windows':\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "# Database simulation\n",
    "plates_db = []\n",
    "faces_db = []\n",
    "\n",
    "# ========== FACE RECOGNITION SETUP ==========\n",
    "print(\"Loading reference faces...\")\n",
    "try:\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    \n",
    "    reference_folder = \"reference_images\"\n",
    "    os.makedirs(reference_folder, exist_ok=True)\n",
    "    reference_image_path = os.path.join(reference_folder, \"person.jpg\")\n",
    "    \n",
    "    if os.path.exists(reference_image_path):\n",
    "        ref_image = face_recognition.load_image_file(reference_image_path)\n",
    "        ref_encodings = face_recognition.face_encodings(ref_image)\n",
    "        \n",
    "        if ref_encodings:\n",
    "            known_face_encodings.append(ref_encodings[0])\n",
    "            known_face_names.append(\"Authorized Person\")\n",
    "            print(f\"{len(known_face_encodings)} reference faces loaded\")\n",
    "        else:\n",
    "            print(\"No faces found in reference image\")\n",
    "    else:\n",
    "        print(f\"Reference image not found at {reference_image_path}\")\n",
    "        print(f\"Please add a reference image at {os.path.abspath(reference_image_path)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Face load error: {e}\")\n",
    "\n",
    "# ========== PROCESSING FUNCTIONS ==========\n",
    "def detect_faces(frame):\n",
    "    if frame is None:\n",
    "        return None, []\n",
    "    \n",
    "    try:\n",
    "        # Convert to RGB (face_recognition uses RGB)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Scale down for faster processing\n",
    "        scale = 0.5\n",
    "        small_frame = cv2.resize(rgb_frame, (0, 0), fx=scale, fy=scale)\n",
    "        \n",
    "        # Find face locations using HOG (faster than CNN)\n",
    "        face_locations = face_recognition.face_locations(small_frame, model=\"hog\")\n",
    "        face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "        \n",
    "        detected_faces = []\n",
    "        \n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            # Scale back up face locations\n",
    "            top = int(top / scale)\n",
    "            right = int(right / scale)\n",
    "            bottom = int(bottom / scale)\n",
    "            left = int(left / scale)\n",
    "            \n",
    "            matches = face_recognition.compare_faces(\n",
    "                known_face_encodings, \n",
    "                face_encoding, \n",
    "                tolerance=CONFIG[\"FACE_MATCH_THRESHOLD\"]\n",
    "            )\n",
    "            \n",
    "            if True in matches:\n",
    "                # Known face\n",
    "                name = \"Authorized Person\"\n",
    "                status = \"authorized\"\n",
    "            else:\n",
    "                # Unknown face\n",
    "                name = \"Unidentified\"\n",
    "                status = \"unknown\"\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            color = (0, 0, 255) if status == \"authorized\" else (80, 80, 80)\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            \n",
    "            detected_faces.append({\n",
    "                \"name\": name,\n",
    "                \"status\": status,\n",
    "                \"location\": {\n",
    "                    \"top\": top,\n",
    "                    \"right\": right,\n",
    "                    \"bottom\": bottom,\n",
    "                    \"left\": left\n",
    "                },\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            # Add to database\n",
    "            faces_db.append({\n",
    "                \"id\": len(faces_db) + 1,\n",
    "                \"name\": name,\n",
    "                \"status\": status,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "        \n",
    "        return frame, detected_faces\n",
    "    except Exception as e:\n",
    "        print(f\"Face detection error: {e}\")\n",
    "        return frame, []\n",
    "\n",
    "def detect_plates(frame, frame_counter):\n",
    "    if frame is None:\n",
    "        return None, []\n",
    "    \n",
    "    # Skip frames to reduce processing load\n",
    "    if frame_counter % CONFIG[\"FRAME_SKIP\"] != 0:\n",
    "        return frame, []\n",
    "    \n",
    "    try:\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        gray = clahe.apply(gray)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        \n",
    "        # Apply adaptive thresholding\n",
    "        thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                     cv2.THRESH_BINARY_INV, 11, 2)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Filter contours by area\n",
    "        contours = [c for c in contours if cv2.contourArea(c) > 1000]\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:5]  # Top 5 candidates\n",
    "        \n",
    "        detected_plates = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            peri = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "            \n",
    "            # More relaxed shape condition - 4-sided or more\n",
    "            if 4 <= len(approx) <= 6:\n",
    "                x, y, w, h = cv2.boundingRect(approx)\n",
    "                aspect_ratio = w / float(h)\n",
    "\n",
    "                # License plate aspect ratio check\n",
    "                if 2.0 < aspect_ratio < 6.0:\n",
    "                    plate_img = gray[y:y+h, x:x+w]\n",
    "\n",
    "                    \n",
    "                    # Display potential license plate region\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "                    \n",
    "                    # Check plate size before OCR\n",
    "                    if plate_img.shape[0] > 0 and plate_img.shape[1] > 0:\n",
    "                        # Apply additional preprocessing to the plate region\n",
    "                        plate_img = cv2.resize(plate_img, (0, 0), fx=2, fy=2)  # Upscale\n",
    "                        plate_img = cv2.GaussianBlur(plate_img, (3, 3), 0)\n",
    "                        _, plate_img = cv2.threshold(plate_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "                        \n",
    "                        # OCR with Tesseract\n",
    "                        text = pytesseract.image_to_string(\n",
    "                            plate_img,\n",
    "                            config=CONFIG[\"PLATE_OCR_CONFIG\"]\n",
    "                        )\n",
    "                        clean_text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "                        \n",
    "                        if len(clean_text) >= CONFIG[\"MIN_PLATE_CHARS\"]:\n",
    "                            # Simulate offender check (in real app, check against database)\n",
    "                            is_offender = len(clean_text) % 2 == 0  # Just for demo\n",
    "                            \n",
    "                            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "                            cv2.putText(frame, f\"PLATE: {clean_text}\", \n",
    "                                       (x, y-15), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                       0.7, (255, 0, 0), 2)\n",
    "                            \n",
    "                            plate_data = {\n",
    "                                \"plateNumber\": clean_text,\n",
    "                                \"isOffender\": is_offender,\n",
    "                                \"timestamp\": datetime.now().isoformat(),\n",
    "                                \"location\": {\"x\": x, \"y\": y, \"width\": w, \"height\": h}\n",
    "                            }\n",
    "                            \n",
    "                            detected_plates.append(plate_data)\n",
    "                            \n",
    "                            # Add to database\n",
    "                            plates_db.append({\n",
    "                                \"id\": len(plates_db) + 1,\n",
    "                                \"plateNumber\": clean_text,\n",
    "                                \"isOffender\": is_offender,\n",
    "                                \"timestamp\": datetime.now().isoformat(),\n",
    "                                \"cameraId\": \"CAM-1207\"  # Example camera ID\n",
    "                            })\n",
    "        \n",
    "        return frame, detected_plates\n",
    "    except Exception as e:\n",
    "        print(f\"Plate detection error: {e}\")\n",
    "        return frame, []\n",
    "\n",
    "# ========== WEBSOCKET MANAGER ==========\n",
    "class ConnectionManager:\n",
    "    def __init__(self):\n",
    "        self.active_connections: List[WebSocket] = []\n",
    "\n",
    "    async def connect(self, websocket: WebSocket):\n",
    "        await websocket.accept()\n",
    "        self.active_connections.append(websocket)\n",
    "\n",
    "    def disconnect(self, websocket: WebSocket):\n",
    "        self.active_connections.remove(websocket)\n",
    "\n",
    "    async def send_personal_message(self, message: str, websocket: WebSocket):\n",
    "        await websocket.send_text(message)\n",
    "\n",
    "    async def broadcast(self, message: str):\n",
    "        for connection in self.active_connections:\n",
    "            await connection.send_text(message)\n",
    "\n",
    "manager = ConnectionManager()\n",
    "\n",
    "# ========== API ROUTES ==========\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"Surveillance System ML Service is running\"}\n",
    "\n",
    "@app.get(\"/stats\")\n",
    "async def get_stats():\n",
    "    total_records = len(plates_db) + len(faces_db)\n",
    "    offenders_today = sum(1 for plate in plates_db if plate.get(\"isOffender\", False))\n",
    "    \n",
    "    last_alert = None\n",
    "    if plates_db:\n",
    "        offender_plates = [p for p in plates_db if p.get(\"isOffender\", False)]\n",
    "        if offender_plates:\n",
    "            last_alert = offender_plates[-1]\n",
    "    \n",
    "    return {\n",
    "        \"totalRecords\": total_records,\n",
    "        \"offendersToday\": offenders_today,\n",
    "        \"camerasActive\": 2,  # Hardcoded for demo\n",
    "        \"lastAlert\": last_alert\n",
    "    }\n",
    "\n",
    "@app.get(\"/plates\")\n",
    "async def get_plates():\n",
    "    return plates_db\n",
    "\n",
    "@app.get(\"/faces\")\n",
    "async def get_faces():\n",
    "    return faces_db\n",
    "\n",
    "# ========== WEBSOCKET ENDPOINT ==========\n",
    "@app.websocket(\"/ws\")\n",
    "async def websocket_endpoint(websocket: WebSocket):\n",
    "    await manager.connect(websocket)\n",
    "    frame_counter = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            data = await websocket.receive_text()\n",
    "            data = json.loads(data)\n",
    "            \n",
    "            if data[\"type\"] == \"frame\":\n",
    "                # Decode base64 image\n",
    "                img_data = base64.b64decode(data[\"frame\"].split(',')[1])\n",
    "                nparr = np.frombuffer(img_data, np.uint8)\n",
    "                frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "                \n",
    "                # Process based on camera role\n",
    "                if data[\"role\"] == \"faces\":\n",
    "                    processed_frame, detected_faces = detect_faces(frame)\n",
    "                    if detected_faces:\n",
    "                        await websocket.send_json({\n",
    "                            \"type\": \"faces\",\n",
    "                            \"data\": detected_faces\n",
    "                        })\n",
    "                else:  # plates\n",
    "                    processed_frame, detected_plates = detect_plates(frame, frame_counter)\n",
    "                    if detected_plates:\n",
    "                        await websocket.send_json({\n",
    "                            \"type\": \"plates\",\n",
    "                            \"data\": detected_plates\n",
    "                        })\n",
    "                \n",
    "                # Encode processed frame to base64\n",
    "                if processed_frame is not None:\n",
    "                    _, buffer = cv2.imencode('.jpg', processed_frame)\n",
    "                    processed_frame_b64 = base64.b64encode(buffer).decode('utf-8')\n",
    "                    \n",
    "                    await websocket.send_json({\n",
    "                        \"type\": \"processed_frame\",\n",
    "                        \"frame\": f\"data:image/jpeg;base64,{processed_frame_b64}\",\n",
    "                        \"camera\": data[\"camera\"]\n",
    "                    })\n",
    "                \n",
    "                frame_counter += 1\n",
    "    \n",
    "    except WebSocketDisconnect:\n",
    "        manager.disconnect(websocket)\n",
    "    except Exception as e:\n",
    "        print(f\"WebSocket error: {e}\")\n",
    "        manager.disconnect(websocket)\n",
    "\n",
    "# ========== SERVER STARTUP ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting ML Service on http://localhost:8000\")\n",
    "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
